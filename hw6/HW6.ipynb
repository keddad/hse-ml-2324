{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LEx3M_MjizK3"
   },
   "source": [
    "# üëÄ WARNING üêà\n",
    "\n",
    "\n",
    "### ‚ö†Ô∏è Important Setup Instructions\n",
    "\n",
    "Before you begin this homework, please note that all tasks were tested in Google Colab. It's crucial to follow the setup steps below to ensure that your environment is configured correctly. You will require a GPU for some of the tasks, so please make sure to adjust your Colab settings accordingly.\n",
    "\n",
    "#### Setup Steps:\n",
    "\n",
    "1. Use a GPU runtime to accelerate the training process of the CNN and proper compile:\n",
    "   - In Google Colab, click on ‚ÄòRuntime‚Äô.\n",
    "   - Select ‚ÄòChange runtime type‚Äô.\n",
    "   - Choose ‚ÄòGPU‚Äô from the hardware accelerator dropdown menu.\n",
    "2. Install necessary libraries and dependencies as outlined in the provided code snippets.\n",
    "3. Execute all code cells in the order they are presented to avoid dependency issues.\n",
    "\n",
    "#### Installation Commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "os09aqKPliMb",
    "outputId": "b039c3e5-854f-4bd9-a2a1-7efb2c386f42"
   },
   "outputs": [],
   "source": [
    "!export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n",
    "!export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n",
    "!ldconfig \"/usr/lib64-nvidia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UhIA-h5n5n04",
    "outputId": "837eb3e2-da48-4b62-b7c5-e27786eea3a2"
   },
   "outputs": [],
   "source": [
    "!pip install tensorrt torch_tensorrt onnx onnxruntime maturin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jpHw8JdPENo4",
    "outputId": "0c8bab7c-12ca-4e1c-cdb5-27c57e947c13"
   },
   "outputs": [],
   "source": [
    "!curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_4cwr9FYFBH-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PATH'] += \":/root/.cargo/bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XBJjzFHIFQkj",
    "outputId": "1e6b4db1-343d-4d7c-d70b-8c8423beddb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cargo 1.74.0 (ecb9851af 2023-10-18)\r\n"
     ]
    }
   ],
   "source": [
    "!cargo --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7CbAqtMlZtL"
   },
   "source": [
    "# HSE 2023: Mathematical Methods for Data Analysis\n",
    "\n",
    "# Homework 6 (Bonus)\n",
    "\n",
    "**Author: Alexander Kalashnikov**\n",
    "\n",
    "## Introduction\n",
    "Welcome to an exciting journey through the realms of machine learning and system integration, where we will tackle a fascinating challenge: building a Convolutional Neural Network (CNN) designed to recognize time from images of digital clocks. This task not only covers the design and training of neural networks but also extends into the world of production-level deployment. We'll dive into converting a trained model into various runtimes, and you'll get hands-on experience with implementing model inference in Rust‚Äîa language renowned for its performance and safety.\n",
    "\n",
    "<img src=\"./images/1.png\">\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\"><b> Your mission is to train a model that can look at such images and tell us the time displayed. </b></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kaN5zcloA3r"
   },
   "source": [
    "# Load data\n",
    "\n",
    "Let's begin by downloading the dataset required for this homework. The dataset contains the images that we will use to train our model. \n",
    "\n",
    "**Follow the commands below to download and extract the dataset into your working environment:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gmBGcsb0oCKP",
    "outputId": "d0d7ed31-f840-4b8a-aefc-322c04014767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aiukalashnikov/anaconda3/lib/python3.11/site-packages/gdown/cli.py:126: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1ZLKpoYcMVBVgZBq2jvB23zR4yHClVfUd\n",
      "To: /Users/aiukalashnikov/PycharmProjects/funny_rust/timer_dataset.zip\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18.9M/18.9M [00:00<00:00, 32.9MB/s]\n",
      "Downloaded data into ./timer_dataset\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1ZLKpoYcMVBVgZBq2jvB23zR4yHClVfUd && unzip -q -o timer_dataset.zip\n",
    "!echo \"Downloaded data into ./timer_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are two utility functions for the start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aKCPA-3ElS_k"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "h6qhQPcElXUC"
   },
   "outputs": [],
   "source": [
    "def read_image(image_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Reads an image from a specified file path and convert it to RGB format.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The image in RGB format.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "\n",
    "def visualize(**images) -> None:\n",
    "    \"\"\"\n",
    "    Plots images in one row.\n",
    "\n",
    "    Args:\n",
    "        **images: Variable length keyword arguments. Each key-value pair should be \n",
    "                  the name of the image and the image data respectively.\n",
    "\n",
    "    \"\"\"\n",
    "    n = len(images)\n",
    "\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fpTc3CwG-Jt"
   },
   "source": [
    "## [Task 1] Exploratory Data Analysis (EDA) - 0.5 Point\n",
    "\n",
    "### Objective:\n",
    "Perform an exploratory data analysis (EDA) on the provided dataset to understand its structure, contents, and the data you'll be working with.\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. **Verify Dataset Integrity:**\n",
    "   - Check dataset structure.\n",
    "   - Check the number of files in the dataset.\n",
    "\n",
    "2. **Understand File Distribution:**\n",
    "   - List the first few image filenames to get a sense of the naming convention.\n",
    "   - Review the targets file to understand the association between images and their labels.\n",
    "\n",
    "3. **Read Targets:**\n",
    "   - Use pandas to read the targets file into a DataFrame.\n",
    "   - Ensure the DataFrame is correctly structured with columns for both the target and the filename.\n",
    "\n",
    "4. **Data Visualization:**\n",
    "   - Use the `read_image` function to read a sample image from the dataset.\n",
    "   - Visualize the sample image using the `visualize` function.\n",
    "   - Map this sample image to the corresponding target in targets DataFrame printing both.\n",
    "\n",
    "5. **Initial Data Insights:**\n",
    "   - Report the size of the dataset (number of images).\n",
    "   - Provide a brief summary of the target variable distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nieGs50xnglc"
   },
   "source": [
    "## [Task 2] Implement `create_train_val_splits` Function - 0.25 Points\n",
    "\n",
    "### Objective:\n",
    "Write a Python function `create_train_val_splits` to divide a dataset into training and validation sets and save the result as a JSON file.\n",
    "\n",
    "### Requirements:\n",
    "\n",
    "- Read image names from a markup file (`markup_path`).\n",
    "- Split data into training and validation sets using the `val_ratio`.\n",
    "- Save the splits in JSON format to the specified `output_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "oP1OSEU3mw2u"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def create_train_val_splits(\n",
    "    markup_path: str,\n",
    "    output_path: str,\n",
    "    val_ratio: float = 0.2,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Creates training and validation splits from a markup file and save them as a JSON file.\n",
    "\n",
    "    This function reads a markup file containing image names, splits the images into\n",
    "    training and validation sets, and then saves these sets to a specified JSON file.\n",
    "\n",
    "    Args:\n",
    "        markup_path (str): Path to the markup file with image names.\n",
    "        output_path (str): Path where the JSON file with train-validation splits will be saved.\n",
    "        val_ratio (float, optional): The proportion of the dataset to include \n",
    "        in the validation split. Defaults to 0.2.\n",
    "    \"\"\"\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "\n",
    "markup_path = 'timer_dataset/targets.txt'\n",
    "output_path = 'timer_dataset/splits.json'\n",
    "create_train_val_splits(markup_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vhi7Kf-dnyho"
   },
   "source": [
    "## [Task 3] Image Preprocessing and Augmentation - 1 Point\n",
    "\n",
    "<img src=\"./images/2.png\" width=\"60%\">\n",
    "\n",
    "### Objective:\n",
    "Implement functions to apply image augmentations and preprocessing for the images normalization and unification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Define Augmentation Functions\n",
    "\n",
    "\n",
    "- `get_training_augmentations(image_size: int) -> albu.Compose`: This function should construct a series of augmentation transforms for training images. You have the freedom to add any augmentations you find necessary to improve the training process. **However, ensure that every transformed image is resized to a square format with dimensions `image_size x image_size`.**\n",
    "\n",
    "\n",
    "- `get_validation_augmentations(image_size: int) -> albu.Compose`: This function will define a series of transformations for validation images. Validation transforms are typically less extensive than training transforms. They should normalize the image but should not include random transformations that would create variations in your validation data. Like the training augmentations, **all images should be resized to be square with the same width and height as specified by `image_size`.**\n",
    "\n",
    "Note that while you may introduce a variety of transformations for the training dataset to improve model robustness, all images, after augmentation, should maintain a square shape. This consistency is crucial for training stability and performance evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "S4p1_0KgnvuA"
   },
   "outputs": [],
   "source": [
    "from typing import Callable, Literal\n",
    "\n",
    "import albumentations as albu\n",
    "\n",
    "\n",
    "def get_training_augmentations(image_size: int) -> albu.Compose:\n",
    "    \"\"\"\n",
    "    Constructs augmentation transform for training images.\n",
    "\n",
    "    Returns:\n",
    "        albu.Compose: augmentation transform\n",
    "    \"\"\"\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "\n",
    "def get_validation_augmentations(image_size: int) -> albu.Compose:\n",
    "    \"\"\"\n",
    "    Constructs augmentation transform for validation images.\n",
    "\n",
    "    Returns:\n",
    "        albu.Compose: augmentation transform\n",
    "    \"\"\"\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Implement `to_tensor` Function\n",
    "Implement the `to_tensor` function to reshape the input image to the required format for PyTorch models (**CxHxW** - channel first), which involves changing the order of dimensions and ensuring the data type is float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "eGsYwaUaKWUR"
   },
   "outputs": [],
   "source": [
    "def to_tensor(x: np.ndarray, **kwargs) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Transposes an image array to the required shape for pytorch.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): image array.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: transposed image array\n",
    "    \"\"\"\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Implement `normalize_img` Function\n",
    "Write the `normalize_img` function to apply mean and standard deviation normalization to the image data, which is a common preprocessing step to standardize input data for model training.\n",
    "\n",
    "**Use the mean and the standard deviation values for the ImageNet dataset. Do not forget about the image normalization by maximum pixel value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZIA5IC22KYyn"
   },
   "outputs": [],
   "source": [
    "def normalize_img(img: np.ndarray, **kwargs) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalizes image data.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): image array.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: normalized image array\n",
    "    \"\"\"\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Construct Preprocessing Pipeline\n",
    "Combine the normalization and tensor transformation into a preprocessing pipeline with the `get_preprocessing` function, which should return an `albu.Compose` pipeline to be applied to image data before feeding it into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hqoKpfZeKaN9"
   },
   "outputs": [],
   "source": [
    "def get_preprocessing() -> albu.Compose:\n",
    "    \"\"\"\n",
    "    Constructs preprocessing transform.\n",
    "\n",
    "    Args:\n",
    "        preprocessing_fn (Callable): data normalization function.\n",
    "\n",
    "    Returns:\n",
    "        albu.Compose: preprocessing transform\n",
    "    \"\"\"\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bs9A8kgKn28C"
   },
   "source": [
    "## [Task 4] Custom Dataset Class Implementation - 1 Point\n",
    "\n",
    "### Description:\n",
    "Construct a `TimerDataset` class extending PyTorch's `Dataset` class, capable of loading, processing, and augmenting timer images for model training.\n",
    "\n",
    "### Steps:\n",
    "1. Initialize the dataset with paths for images, markup, and splits, specifying data kind (train/validation), and optional augmentation and preprocessing functions.\n",
    "2. Load dataset splits from a JSON file and image-label pairs from a markup file.\n",
    "3. Implement `one_hot_encode` to encode targets as OH vectors.\n",
    "4. Implement `__getitem__` to load and preprocess images, and apply one-hot encoding to labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TpSIdGz-n0NC"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Callable, Literal\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class TimerDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset class for loading and processing timer images.\n",
    "\n",
    "    This dataset class is designed to work with a specific format of markup file and\n",
    "    directory structure. It supports optional data augmentation and preprocessing.\n",
    "    Labels are one-hot encoded.\n",
    "\n",
    "    Args:\n",
    "        images_path (Path): Path to the directory containing images.\n",
    "        markup_path (Path): Path to the markup file containing image names and corresponding time labels.\n",
    "        splits_path (Path): Path to the JSON file containing train/validation splits.\n",
    "        kind (str): Type of dataset to load ('train' or 'validation').\n",
    "        augmentations (Callable, optional): A function/callable that applies data augmentation.\n",
    "        preprocessing (Callable, optional): A function/callable that applies preprocessing.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        images_path: Path,\n",
    "        markup_path: Path,\n",
    "        splits_path: Path,\n",
    "        kind: Literal[\"train\", \"validation\"],\n",
    "        augmentations: Callable | None = None,\n",
    "        preprocessing: Callable | None = None,\n",
    "    ):\n",
    "        self.images_path = images_path\n",
    "        self.augmentation = augmentations\n",
    "        self.preprocessing = preprocessing\n",
    "\n",
    "        # Load splits\n",
    "        # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "        # Load markup (image_name, (hours, minutes))\n",
    "        self.samples: list[tuple[str, tuple[int, int]]] = []\n",
    "        # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def one_hot_encode(self, time: tuple[int, int]) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        One-hot encodes the given time.\n",
    "\n",
    "        Args:\n",
    "            time (tuple[int, int]): A tuple containing hours and minutes.\n",
    "\n",
    "        Returns:\n",
    "            tuple[torch.Tensor, torch.Tensor]: One-hot encoded hour and minute tensors.\n",
    "        \"\"\"\n",
    "        # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[np.ndarray, tuple[int, int]]:\n",
    "        image_name, time = self.samples[idx]\n",
    "        image_path = self.images_path / image_name\n",
    "\n",
    "        # Load image with OpenCV and convert to RGB\n",
    "        # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "        # Apply augmentations\n",
    "        # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "        # Apply preprocessing\n",
    "        # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "        # One-hot encode the label\n",
    "        # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "        return image, (hour_label, minute_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing:\n",
    "- Instantiate the `TimerDataset` class.\n",
    "- Retrieve and visualize a sample from the dataset to confirm correct loading and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "mW7XPjHKn4Q8"
   },
   "outputs": [],
   "source": [
    "dataset = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "0kpMxgdNn5zl",
    "outputId": "ede0e515-031a-48f3-eb3c-4dc577a05e17"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGZCAYAAABmNy2oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHwUlEQVR4nO29baxtSX3m91TVWmvvfc499zbNazemGV4bMxmZduIQj9HwYixoIIzAnhAPaJrYEznwIbFsywQbCcm2kFEUM7GwDRo7YAlpHBzGQRYi1mAwIRkYGhNhjQ2MsMObG3DTTfc999y993qpyofLVDinnse+x+F1+vlJ98OtU2etWlW11n/v83/W8w+llAJjjDEGQPxWD8AYY8y3Dw4KxhhjKg4KxhhjKg4KxhhjKg4KxhhjKg4KxhhjKg4KxhhjKg4KxhhjKg4KxhhjKg4K5juCt771rQgh4CMf+ci3eijG/AeNg4IxxpiKg4IxxpiKg4L5juTlL385Lly4gE984hN4znOeg8PDQ9x000345V/+ZQDAhz70ITztaU/D4eEhnvjEJ+K3f/u3T/3+3XffjVe+8pV48pOfjAsXLuBhD3sYnvWsZ+EDH/hAc67Pf/7z+JEf+REcHR3hhhtuwEtf+lLceeedCCHgrW9966m+H/nIR/DCF74QN954I9brNW677Ta8/e1v/4bNgzFfbxwUzHcs0zThxS9+MZ7//Ofjne98J26//Xa8+tWvxs/93M/hjjvuwI/92I/h937v93Drrbfi5S9/Of74j/+4/u69994LAHjta1+Ld73rXXjLW96Cxz72sXjGM56BP/qjP6r9Tk5O8MxnPhPve9/78PrXvx5vf/vb8fCHPxwveclLmvG8733vww/8wA/gvvvuw5ve9Ca8853vxFOe8hS85CUvaYKHMd+2FGO+A3jLW95SAJQ777yzlFLKHXfcUQCUd7zjHbXPNE3loQ99aAFQPvrRj9b2e+65p6SUyk/91E/J48/zXKZpKj/4gz9YXvSiF9X2X/u1XysAyrvf/e5T/X/iJ36iAChvectbatuTnvSkctttt5Vpmk71fcELXlBuuummsizL3+rajflm4m8K5juWEAKe97zn1f93XYfHP/7xuOmmm3DbbbfV9htvvBEPe9jD8JnPfObU77/pTW/C937v92K9XqPrOvR9jz/8wz/Exz/+8drn/e9/P46OjvDc5z731O/+6I/+6Kn/f+pTn8InPvEJvPSlLwUAzPNc/z3vec/DF77wBXzyk5/8ul27Md8oHBTMdywHBwdYr9en2oZhwI033tj0HYYBu92u/v9XfuVX8IpXvAJPfepT8Y53vAMf+tCHcOedd+K5z30utttt7XfPPffg4Q9/eHO8s21f+tKXAAA/8zM/g77vT/175StfCQD48pe//Le/WGO+SXTf6gEY863gbW97G57xjGfgN37jN061Hx8fn/r/gx/8YHz4wx9ufv+LX/ziqf8/5CEPAQC8+tWvxotf/GJ6zltvvfX/z5CN+abgoGAekIQQsFqtTrX9yZ/8CT74wQ/iUY96VG17+tOfjre//e1497vfjdtvv722/87v/M6p37311lvxhCc8AR/72Mfwute97hs7eGO+gTgomAckL3jBC/CLv/iLeO1rX4unP/3p+OQnP4lf+IVfwGMe8xjM81z73XHHHXjDG96Al73sZfilX/olPP7xj8e73/1u/MEf/AEAIMb/7y+wb37zm3H77bfjOc95Dl7+8pfjkY98JO699158/OMfx0c/+lH87u/+7jf9Oo05L84pmAckP//zP4+f/umfxm/91m/h+c9/Pn7zN38Tb3rTm/C0pz3tVL/Dw0O8973vxTOe8Qz87M/+LH74h38Yn/3sZ/Hrv/7rAIAbbrih9n3mM5+JD3/4w7jhhhvwkz/5k3j2s5+NV7ziFXjPe96DZz/72d/MyzPmb00opZRv9SCM+U7jda97HV7zmtfgs5/9LL7ru77rWz0cY75u+M9HxvwNvPGNbwQAPOlJT8I0TXjve9+LX/3VX8XLXvYyBwTzHxwOCsb8DRwcHOANb3gDPv3pT2O/3+OWW27Bq171KrzmNa/5Vg/NmK87/vORMcaYihPNxhhjKg4KxhhjKteVU8g546677sLR0RFCCN/oMRljjPk6U0rB8fExbr755lPv15zluoLCXXfddeotT2OMMd+ZfO5zn/trVXPXFRSOjo4AAJ/5zOdw8eLFUz8rmf9O7MamrWCgffM40/YkglkOZNhp17YBiEtP2wP4wKfMvwn1fXvOOfNxI/L2buLd576dlzAuvPPAr2cB798j0fZCxhL4oTFmscgL1yiknp+zQ9t/AZ/vvIg9kfmWjd22bSyrtg1AEZ+SAvg51R4P5Hpy4MeO4gt2nvlcgaxnFGu5iI2VtnxBy4bMFYBMjp/Bj9EXdUG8GWnPjsIPoSZ8EY8r0cw0NGniazzzRxO6WTyEuuvX54w7vm5hzecwiMvvlnadSy/28tge+/LxZTzqsY+uz3PFdQWFf/8no4sXL34bBwV+bAeFB0pQIIN/oAeFXgUF8TB2UGgP/fUICsO3R1CoP/sbUgBONBtjjKk4KBhjjKk4KBhjjKmcy+YizgvifPpvnfPA/7YWchtv5sz/7h0CP4b6e3MX2uNk8bdmiL99Tkn8AV1B/xQp/sYbxd+JF/7HwpTadnKJfy0J/O/KyyjmdmjXR/2lsStq3dT2EX9vJccJ6m+2JIcDADnxsSyl7d+Lv52qv9mqvxLnyMcStu1vhA0/5yzWXmx9hJ5tOJEfmsUeH9q8HgDEsqHtKbR/95+viryZ+Hu4mtwJbX6nV/lIkYCZxVA6uaDtcbYDP/ZGVSbueDvLyQFAJo+VLPIVa3GPq7QMI6jP9R25TnEtZ/E3BWOMMRUHBWOMMRUHBWOMMRUHBWOMMRUHBWOMMZVzqY+mkDCFMwqIiafhM1FVRPFmX56Fginx4U1EJRHF25FRvOmbxJunRQiHMtEEBPHW7SDkBkqVFOLVdhwbfu3ilOiEQiYRVQ4AJCKnmkXfHPkcZvFGcz8JZUps5zCKcypVDlsH4JppY3vw8711qxRsKXIVz9KRt9yFWmdY87XfCwUKe4NeyaPUXg5BKNIyb9+T469W4g168dZ+Eo+UTNRXRSgDF/FmeSfGsg+8f08+826EAnKZxaMw8UmPvbgnyDkHoWxSz5oo1pmZHEThBhHJszNfZ+kcf1MwxhhTcVAwxhhTcVAwxhhTcVAwxhhTOVeiOfV7pP50kjcLe+JIksFFJEmTSJKKHDYKsUlOwg55FhlLkZtCErnJhfh4F9G5CKvpJJJTUzlo2nqRUe6EXcIi4juz0ACAZd8eP/ClxCLsxFciIciswAFgWdrjBGEBoGw+SuLZuXhWAAFgXvhBokj8Cfd1ZGH5zkaSlVmI+Pi1WvNNXkgCXuRIEYV9wTxzO4vY8T2xmtpz7lVfcf8sIovP5nwR94PMqAuBwIp5SwCYEtnjUVjpK5t+9bF5Uvdb2xaFUAPCgmYSAolELDqS2m9zW18mFl5zpul3Xb2MMcY8IHBQMMYYU3FQMMYYU3FQMMYYU3FQMMYYUzmX+mg3RwxniqKIWiiYSLzpRYHxIoqHJKF8yKSoRlGvqYt3xpWNAisEA4jyJuIV+EkooSBUL9QuQlh8ZDE+pSgBd2hASuumTYi9pDKD2VYAQCLFZwCgsIJMmQ8wiwI53SIGwxZIjG8WkpJM1FEAAGEXwSxUelVcXhUkUsohUni9p4V3AAhRSbdWt7eSMbWTqJRaEHu8CNVczzbRpG5CrvYaRV2sTthldEv7C0HYc6g9PikLETGWMLaLUQYu6wtEMQforRLIc0LNdwjt/Y0iHgZn8DcFY4wxFQcFY4wxFQcFY4wxFQcFY4wxFQcFY4wxlXOpjw5CwsGZjPmkPISIJ0cRHkdBeJ3MonAOER9h6YRXEB8e5iLUOqLwxUJ+0E3Ch0cpgaSMh6gn2EVCe/+MYuADU/yAfxoQYh2k2PpYAUAW3i1RFQhiyiGpMuKDmUShop50n0UVE3FKBOKVAwCZqFgAIBMJSlzzY0ys6hSAbhYKO9rI989eKJiUnCwp/yjyC530FeLn7MU9zgrnBHF3xlmpvUQhLWGUlYn0bp+5H1Qv/ImEdZj0HJqIZ1UvitvMyuNJtEfW3vM5GUN77WOv9IVnz2OMMcZ8FQcFY4wxFQcFY4wxFQcFY4wxFQcFY4wxlXOpj0q49u9riUl48cxtvFHeMqKwFyAURXls1RNKyaB8XjqhMtoJFc+a+Y70qkybqMokFE+JxGYh6sISudHNWihklkmMcd3OC6v2dW0sYm4HPldZyF4KUaz04nNJjvwYnRjjxGQiQh02qz0xKp8f3kxVTFko7IS6pQhFDbXLmYXCThx7Ef5Ewi4HiahbilDS9RNXpAHEcwdAJDdcEQq7SexlJbJahFon5facqd/y8QmVFcTczuTYANCTqmnS4klIm3rhNzWT/p0wN+un1j+KtTH8TcEYY0zFQcEYY0zFQcEYY0zFQcEYY0zlXInmfc7Y59PJjrVKopDEUha1PRJJzgBAFunWSF6lF/UqoHwrxFCwFueciTVAl8Vr4yK5Ow28PZFklrLQACmOAwDbxBNOG/E6fiafB7qFH2OZhB2BKjQiCgQtLClWeAGSyIqEAFhEArpndhHqtf6FJ9y6XuwKZVOwkESm+pg1C2sJYa3BPq9Nwp8jittYJSGXKBKOzIVE7fGerxu1bAGwEOMOoSORNjFbcf2DmkJiK9MLVcsk7DlEnllba5C93498gKUTwg5VZIccZiJ7EAA6NrmiwFDT7bp6GWOMeUDgoGCMMabioGCMMabioGCMMabioGCMMaZyLvXRunRYn7EZUMVtEnFjCMISYw6iqIRQoLDX4wuxobh2EN4cxGvqSxKvzBOLjln0ndZclrMRhWMyKSpSFmHz0PM5Cao6kFC9hH27bmUj1FGiONAohCnC/QKJKSWEC8cUxev7wkJk7lo1TM7cimEQ9g+j2Cyd2J+0KI8oyrIIRU2nlEBj218IZJQ4ShaCwSxsMcjCBVV5SdxvMfBNEdicK3ubkf9gtRJWIUIFx2xOFnFSISaCWHpkIXfsCrmvhDXL0onCPrMYIzuOEIGFpT12kBN+Gn9TMMYYU3FQMMYYU3FQMMYYU3FQMMYYU3FQMMYYUzmX+mjp5kZtpDLlmRRxSaL4SlpE4RQxjp4Um5iVV1AWviO9KBAjpAxMaBTFOZPwGFmECiESVcAs/INCEUWNhLIJnfDtIRfUieImEOcchOIpMx8icBXG0guFkJBVMA8dgKtHBnBlDxFmAAB64XtVet6+J4Wk1r34nCX8o0YxmC626zOJa18LFZxSQkXRfyTNa3E/0KJGABZRNKgjhXBmoUYE8RkDhIIJQFLyK+KVlMXyJDFZiyh4k5SQZ0982XpVXEv4MIlqQkzAFkSBoTm2c8jaGP6mYIwxpuKgYIwxpuKgYIwxpuKgYIwxpuKgYIwxpnIu9RFCvvbvaxhFpvyv7v140/aJL/4b2vfgwhFt/8Cfvk2MozVWmkRFpXRMTJgAXD3kyod/9D2vp+1M3XPpIY+lfW/qHknbM7ctQplaxUZkZZYALIF7Ao0LV/GMQiH0v33gtU3bPHC91xfv/re0/a6Tv6DtK+JNBQCv/8efa9qCUKtshYJJVpIjOzkLVUpSJQB7VTWML9xADv/v/vLdtG8QPl4f+3Pe/yP3/kHTVvjS46EXbqbt+4mrrw5FObGT0s75WlQ7u+URT6XtF2auGnv0zX+/abv1lrYNAIJQ7/3Ge/4pbT8Y+B46uXq5abu/nNC+l0Z+n1wVcxVFBcBx3jRtyptpiPzZ9JnjP6Ptq107xh/67p+hfZ/7lJ9o2tLiymvGGGPOiYOCMcaYioOCMcaYioOCMcaYioOCMcaYyvm8j0psvEAGoYjYkTJRmzVXYKSRZ+FnUWVrmNt0fl6u0r5FVA1bXRE+IOEKbV7H9pw9qZgGAPGC8GIRBKI0UpWdCp8qTELZFPZcPdKtWqWJtE9aC4+j+3j/WSg2euahxKqxAYhC1SasXpCJd00SvkKTMK7pxVhK4uvcE+XUvD/gfTuuDgui8lo4bsfeCR+evbiNDy7yzZJxkbavx/ubtklV9BOVC/es5CKASO7xnqidrnXmi6zUe2HL12dPPNU2rFoegN2Gq6bijl/PWvgI7Tbt8XvxfJuYZA7AsuXrnImvVhfEviJbXAjJGvxNwRhjTMVBwRhjTMVBwRhjTMVBwRhjTOVcieaw6xCGM7+y4YmOeNImfrsrPPE39vw98DDyLPZQ2mRO6trXywHgirJ/WInkoSjwcSW3SbEHsaokAMrCMzpFWHFEUiEmqEIjIsE3kPEBwBJ5ex5JMRBRfOVkz8/Zrfn1BFEgJ3SsP/9cMoskflEFSOZ27KqgSidsFGZhixF3otAMKyR1JGw4Zp4lnXaiaBBJKu43F2jfR3QieaqUAztu9bA6aMc+FJFoJmIPABjE+qTU9h9VQSvhxrARopYsEtYrIjS4f8sfeXnNT7oW9hdXAt+fHbmvEPizaRbPtygey2XXPstC4H23JInN2vj5jTHGmK/ioGCMMabioGCMMabioGCMMabioGCMMaZyLvVR7DNif6bIDvhr+ptdq7ZYjngMCoUPY7zA1QkzU2zshYpDFI4JV8VYRP2VSIq7zMICIIkCObNQZuTQqnW6LR/HBKHK2XGFQ1zzeZn69tX7LbEmAYCOKGEAoBzztd92bXETAJjJOk+jUH2sRGUSwdQRJdDEj52FRcEi1jNyMRVm4rmx7Lmyp6y5/cW0Fio4orArpGgMACxHvEhVHg5p+5C56oXZZay3fB1WD7+Ptk+iaFIk4qs+8/XZD0LxNIrnwYG4D3N7Ex0lfu2XN3x99onfExdHvvenVau6PN5z65xLK65Iu+eYn7MHUSmuxP1DnmOjeLadxd8UjDHGVBwUjDHGVBwUjDHGVBwUjDHGVBwUjDHGVM6lPprTtX+nD8C9Xlhtl2HLM+VcfwEczTxdfjK3B1+Jaj9jEeqjB/FxLx1XbHQLOb5QjuRJ+PMIFcsykevc8KVZTVz1MPdc4YCt8PMhnjYbotYAgLQ9pu1h4tc/QFVDaceSolKkCdWU8JVKxCtqJz7zHBAVBwBAqGGKGMtmaa9zgxv4Meav0PaBKM8AYCZeSVkoTfbUUwoIQpGn/KMCuZf34u7cioJEw4bvN6a8K6LqSy88wnYQShviewUAE7n3t6Mo3CW2xBD5WOZJ3CukEFJX+DNl7IS3m3imBqLsKsIPitqPiefPWfxNwRhjTMVBwRhjTMVBwRhjTMVBwRhjTMVBwRhjTOV86iPcgxmn093zzD1DPnn5/2zaPvbpf0n7BqEI+O/+89+n7ZH4kZwc30/73jt/gbZfEP4v//z9P07b89ym7r//u++gff/B33ssbQ9COYOetAtVwZ2ffTttf+8n/lfaPkSuHvnPbvmH5JR8fPdf5cqmvP8sbxdVxkAqmw2Jn3Niai8AXcfVV2w5SbGvayxCfSO8n8IiSoGR6n2fyX9Ju6bLXK3zkBu/m7bffumJ7TE6rib6+7f+E9oeiBIGAGZRkS0SJViIXJazCPURU5gBQLe0c7WIqm5JqMNe+ey30PZJ9F+R/bwE8TlYFKlL0gyNj/3T932safvSPR+lfU/Ec+/KIz9P2xe0z9pHPPw/5X1De0GsjeFvCsYYYyoOCsYYYyoOCsYYYyoOCsYYYyrnSjR3l0d0ZzOgogBLOiFJjYkXgkHkScWUxGv6LPG34seIIpkDUVDleMv798RiIIgkbidsLkZSCEaNJYlh78T1hMiToXEWVhwHbRa2u58XiOkGvm5ZzOFh2fPj7EnhmMizwcr+IheRrCdDGWaxfzIfd1ZbpefJ00wS5xe2fI3nAz7uA5H7203tWmTwdVBCjUkkfaNIthZSHCqLR0Qncu+LEA6w2jukjtC1cxLLEgBIwuZC3csgiWZVeAnCKiMMfH/mrPYEWdCF21yUQ36/pS/TZsSZCD523G4jkM3M2uh5rquXMcaYBwQOCsYYYyoOCsYYYyoOCsYYYyoOCsYYYyrnUh+F1QHC6nQmfbcTRWwO2ngzqIIdA1cPRKEqWMhr+kPh9gebnqtB4sj7Y+DqiYxd09ZloUxIXJkwTKKwD+leRNEg9dr9ahYFYgIf43zcnrSsRV9hrxBPxFwdCJXZul1P4biAJFRJYAWJABSiehGXjizmqhMFmXYLv03Wud1Doyh4s9ryC72y8OvZzO05d4mrurLYE0kUiBHOFcgdKYIkJEJ5xa8ni7kqbO+LcUehGpvF/dYlfhymDlvEnuh7td94M0SBoC6QPS7WLQi7lSieH1epTYx4RhJFJ2uj57+uXsYYYx4QOCgYY4ypOCgYY4ypOCgYY4ypOCgYY4ypnEt9tKxnLOvT6fg88cz6OrdFaU6UX8jxVX6+rVDrbFp1wnxfqw4CgEUoGfpFqI+E2mBzcNR2JX5IAJCEMmEU/kRshEFIZ6JQfSBxZcHccXXCftUqNg6F39Bwwidlv+Zrn4THSiG+M13f7hMAgFAIQSihApWVCIVMx7f9LIoMrSe+b+fUzku3E6oUol4DgCPwgkRXicqqW/O+s/hsl4QHFTo+55nI4KI49iKUgb0w7crExywKH6ssvJmyVJ4JBQ7a6+mZ1A/AKG78xApgASjKb4lUe5r3fB3mDV/P4z0fC1MahYUr/QairmRtDH9TMMYYU3FQMMYYU3FQMMYYU3FQMMYYU3FQMMYYUzmX+mj6yg7TGZXHhYOLtO9V4jk0ELUGACAc8MFtuFKgIyqRfeKKikEk3PPIFQEXWOUkAPcTf5W4FxXWslAPCPUVWLWqhase5lEoLTo+lp1QeERSaaoXu6FfcSXUoVBg5JmrRAJRvezPVvL7KqvEBzOqwl6ZeevwORECJmTRPonPTqyCWYp8X50c8o04bfleWbp2XpJQ4xVxQUvmc5jYXAGIaMeofJV64vFzbTC8me039EIdJsY9dHyuZuEfxZRTOzG+nvg+AUASaiV1nfPYqoFWB0Ltdsz3ykooBueJeW1x5SbT7qm6dWfxNwVjjDEVBwVjjDEVBwVjjDEVBwVjjDEVBwVjjDGVc6mP7l/vkNenf2U/cUXAd1363qbt0n90ifadCvfvmIQSiKk+Lqz5sXdL61kEAPNFrnr5yv4e2n78lVYpsH/MFdo3Ja7W2QvBxkAuU7jW4Ace90La/uRbnkXbN/sLtL17UDtfol4a7t1epu13fvr/ou0X1lznMBPRyyoLpUUR1cSU6IV8vPln7/pR2ncROoyn/92X0Pbb/s5/wccSWj+jvzz+Iu27Fte56vn+fFj3mKZtOOL3WhReW0mVtRPVCJniLYpxLwufwyB8pdCzqntijfeiktpGVF7L3Fdq17X9B7YJAWRxzmkl5G5ClfTFr3y0aXvPn/3P/JyBz+Gr/uE7afueXOaFC4dtI4A0E/VacOU1Y4wx58RBwRhjTMVBwRhjTMVBwRhjTOVciebVNmLVn44jJwtPfnWlbR+E7UAvkooyYrEcj0qiCAuAVeTtRRTVOJpbi4Y4ChsB8T55EPYXGNorFe4CiKJwzAG4Vch8URR3Ka09yV4UJEosiwtgveaD3O35cTqQ/lEkMveqgJGY8470v8DHtxGFcBaRPFTJbXb7HB1wwcNMCgwBwCCKDJWhtS8IhV97EOsjah1J+485EmuaIOakv17ThHrSpiWLolPLiluC9EJ4oorsrMnYlygKffV8TgZhEwPyfAOAy+QxtAgbjv6AX+eeFowCDg9aYUvY8vt+WbfHXpKL7BhjjDknDgrGGGMqDgrGGGMqDgrGGGMqDgrGGGMq51IfdYjoy+lMfxCWBttd236/eDU+RfGqduBZ+InIj3pWxAMAijonV+XMwuwhYNu0jSqmilnNRIEBAB1RJa0iV6WcFN6+TNyKIqmwv27HohwK8igUG7y+B8a8pu2FrhFXjXVCKVHEMmNqfzCpcUMVthH2HMIWI5L1LAvfV0HYwXTjjbR93LRzGIUiKwZhByPWU2jgAKLIy0LxM858jZOQ3mVSkGo18HttUUpC8TyAsPkAUerFRRUeEuMWh46TUNjF47YvUQIBQJiEmc2W37T7pbWsOWQFugBEIl/slKTx7O9eVy9jjDEPCBwUjDHGVBwUjDHGVBwUjDHGVBwUjDHGVM6lPtrnDrt8+le6UfiREAHBXhTTORxbZQ8AjMwrB0Ahqo9F+PAAXLGQwf1SgrInIkVC1uwiAYziGCHx6WbWNbOQPbDiGQCQlcIhcIUD1Vos/NhlxT87hIErbR48iAIs7JICH3eMfBKLKsoTyRjFR54ilCOjkDZ1qjAL8dWKrGISgHnhqrFdx+f88KTdzxPxyAKAWeiJerH3A/i65alVFCn1zdCpQj18fVLXjnFb+NqvhB+WGkzI/L6ayPokUXdoWfO1V15jcyf8wLp27IPwX9tn/jycL/LnYSFFebbCJ4ktj6gj1OBvCsYYYyoOCsYYYyoOCsYYYyoOCsYYYyoOCsYYYyrnUh8dxILDM5WL9iILz/xY+syVMEV4miQRszLxucnC02SO9/HxCeVDGYQSipSx2vXCJ0l5CAnvkUDGrgo+KSXD1cwVJb1QzjBRRSIKKwAIQShKdnx9rkhzHQKp9vXVs/LuQj3CTnkoKt3thF9MPwkllFAllbldt5G0AcB8wI2iUs89hEIiSqDlhI8PfNzKs0ldJxMrdUJ9My2iiuLE1zMTE64g1j4KHyIq0wNQROXGwko0iudVJ9SIe6HgirT8IzDGdt2mPT+GUlldFIrOkVQMDGtxbKKCWhVZQvAU/qZgjDGm4qBgjDGm4qBgjDGm4qBgjDGm4qBgjDGmci710aUbbsHFixdPtWXhUROPHt203fIw4VsjzpdmfuxE/G/+4sq/o30/d+XPaPv6hGf4v++W22n7SNQTNx89jvbthaBGCFMwL+119r1QDXW8UteNosLcKI7TzaR/4J8RElFeAcB0wNdzFJ4uU2r7R+FvhVFVGePKmZ5M+o//4L+gfUvPr2dQQijhWZXm9heuzH9B+1455iqRy+FLtH2f/7Rp64U67P/4yK/R9rLhFzSD+zCtNm1lr5WQwb34+/5H2q4eKMOm/clR/2DeeRJHUcZkQsWTiEJoIR5M137A1+dT/88f8u4b4R+Vv9K0PfqR/DlRwgFtX+Em3v4gck8I3ydS6A5CBNXgbwrGGGMqDgrGGGMqDgrGGGMqDgrGGGMq50o0I87X/n0NeRY2F6lNikxRJT35K+NTJzIjqU2gbZYrtOtqzxNCsRPJUFGwJO2I7QB4gZRFeTHseHvs2+tUNhezOGdceAJ26Pj1g9grLCz5DCB33J5kXPggb+j5GMPVdp1TJwoPiWI1ZeT7baG2HSJBvOVzMon+UUghArFGGO+jXREP+bEXsdBDbm0xZpF8xyVRBCkL+xhRqCiu2rEkYikDAKXjlhvIbbIaALq+Pc5U+Jx0RHgBAGHN+4/C/mJg15l58n0R9/2xKCZ0SexD5DaJ3838WZNFxR9yCABA3JHrF/Y23UHbt5OSnjPnua5exhhjHhA4KBhjjKk4KBhjjKk4KBhjjKk4KBhjjKmcS3005g7jmdeqRbkOLKFVG8xCJdAPohjIwpUPrNjGbi0KpAhbhP2aK2SGxBUby0CUJlGpO0SsXQm7CFIkpBNCgY7YbQDAUoTiqfAiLqxGSBLbIWU+h4eiGMplUYAEm1bdMgVe1AjCKqMnyjOAq5LSivc9AbcXUIVTspgXpuYo8SLpCYTA1TqHou7JfcR2Ydzx/bYduYJpI5RqecUVQuFyO19bMb6l8PVJQsWTTx7SNl4U6ps1v55p4ntf1Jmh/jlF3D8deV4BwINIsTAA2Aml2kwUXHMWz5odn8MYhWKQPJsmocjqSZGqJApXNee/rl7GGGMeEDgoGGOMqTgoGGOMqTgoGGOMqTgoGGOMqZxLfTSUBcNZpUwn5Akk3qgiJrPwQCmJKxmY2GAeucomE88VAOj23M9n2nKlwL5vpQyDKO6h6sYI8RW63Cocgih4ExZ+8CAUGHuhqCEiCUxBFEEiPlYAAKE+AvGJAoBMiqR0Yt2EaAyZ+A0BAMheORZ9h4GrO1YLN50ZJ1GYhRS9iYXvK+yPaPNu5p5dB2PrfdRd4Gv5lZlf5/EkfHv27bEBYLxwqWnr6d0GBCGPW8Q5QZRQoRzSnkkogaLwIcpij0dSTCmIPVvE/bYlykAAOBDKyET2Soh87Y+P+DosonBOieR6aE9gIj+Z1L1zBn9TMMYYU3FQMMYYU3FQMMYYU3FQMMYYU3FQMMYYUzlf5bUSWwmNyMKzTHlRhdSK8MqZ+S9MRIVwwEpvAbhH5OdnoapIB1yBsiaZ+zBxPxtiW3Pt2ERlBAAT8UpS6hssojrYyJUFaoGZwCFGrrJZrvJxLyu+bodRKDPIaOLA10eJeEIUqheyuVaZK3v2s5gVoSbr1sJvCu28DMLPZyd8iErh7dupVWXFHR/fdKIUNbQZY+KeOwdECTZmvpb9nqvGlgtcrTPt2vZDUQVtIs8OAEhBXJDw/dqRz7xr4da2H/neLzMf4xj5cdLUbty9qGi4Udcp7nGQ+3Me+cOmkOGJp2x7muvsZ4wx5gGAg4IxxpiKg4IxxpiKg4IxxpjKuRLNU7fF1J1ObPQie8wKzUyJJ4SiSCjfnT9H28ftcdP2oS++h/b9vz/1Nto+FJ60+++f87/T9quhTVpuDlpbAABIIvGlau+krv1BJknMv469yMGtRBGbPLVLn1Z8HeJKJBWFy0UUyeC0tNe5VZYGK574W808wUccDQBhozAc8MnaS9GESIZP7Rqp4jN5x601Lq1upu2rowc1bfGhfC3/yT94HT+nSJzfffcnaftnpk83bZ2weXjzB19J27HwdfuhJ97RtD31cf+I9u2F8GQpIqEe+b3Ssc+8wrFkJUQg7//Ym2n7Tuyh2x7xQ03bC5/y39C+g0g0Iwg7D+JlU4T1R1ratRf1qRr8TcEYY0zFQcEYY0zFQcEYY0zFQcEYY0zFQcEYY0zlXOqjboroptNxZE5CsUKED51Q/AjHCeT7udrgcNcqPPp4mfYtQg0xioo3V1fKMqBVGzAFDwBMwv5BiK8QM1EyCKVAFIqF2HNfiEDmCgBS1w5mp4rmBH7so54rgbJQcmRi6bBO/HpmoTIS9UeAmdhFCCuCSeyJVS8sA8QpQQqzXL3Cr+fCAd/7acOPnokVxSF3VUEQk7KwfQWgU/cbETdFYR9zw5rbc+DqAW8mdhlieIhCvZfUDZTFBYV2P2dlqyLsL2Zhk5OF5QZ7JKjrOVnxvXIjbQUisQUJ4n7YkVt5vE6fC39TMMYYU3FQMMYYU3FQMMYYU3FQMMYYU3FQMMYYUzmX+iiEHuGM/0YS2owyk+y8PBs/xiwUQtNhe6CuHNG+8ZC3SwUKKZIBAKwuSxaKnyiq7MQklA9ElROEsgfC/0XZmqjDgPjFdKK4RxDrc1UIUJSqBOT6peBJ7JUwi4I/ZOzLSswKtyEChI9MCKL4UGoLMl3q+J7Y7/gcdhuuDutW7eSeqMpLQpWTMlc8jUJNdim059wmvhDbLd/jw4aP5XDdnrNkUUlJqMDUuo1JFALq27FnUeyoEw+ncihUY+z5BmBFmvfCJ6m7LNRUDxUqTbL3F+InBgDk0mkbw98UjDHGVBwUjDHGVBwUjDHGVBwUjDHGVBwUjDHGVM6lPhq7BeMZhUZYeGa9J4qVLGQpWVS2UiKW1dyqRGZRqSzfL8YnyhBNC1d4JKL86EQ6P3XXaTLyVcrUqi2WXigqhOdKJxRPY+LKmTi1Cgcl+piXVmUDAEFU9lrvRIU9ck4QTxwAENsKs/BKYkNZTVyusqx5JblZlOVaRt4/d610qoD37Zav0PbdlhsaPWRoFyPvuVJJfbZbEr/+XPgeH0n34QI/41L4XF0W5fiWmVQCI95R1xDX0/H9FoX6aCLHiTPfy1PHr2feilJtG77OV8nz49Ker8OVTnhzQfivdaRaonruEc+qokolnsHfFIwxxlQcFIwxxlQcFIwxxlQcFIwxxlQcFIwxxlTOpT6KCIhnNEFdFv5Eoc1+p8IVP1HEpvUBz9pPV0nbjqsEElGIAMAwCE+TQ+Hp0rUqkasnl2jf1QFXQ2yJAgMANsQTKApfIZB5BYAglBy0qhuAricnEAqmQfj5FLFu+RJXVRTi0aOUZ/LTSuB7iApQRImxIjx0kqjKFYVqIxI1SOmE4mdzA21fCb+pTNRu08CrCypVX4lcaROFpxhSq6gZr/DrGcW4N6R6GwDMpAqaLAEn/IlU/2UW+zO191sUT7yuiLH0fL9l4hMFAJH4mO0Cl3AtQkkoBEUIsR1LEf5WidwQSXivncXfFIwxxlQcFIwxxlQcFIwxxlQcFIwxxlTOlWjuco8un07IZJWfIZYBoyiQEoTVwf/0+/8tbT8iJWVu/TvPon3/66e/kbZPiSenDvMhbZ+XNql8UcxeHnlisleJHpYriuL1+pnH8SISYqGIojTspKJYyyg+OxQhMsiZH2ciy6zsRkoQCTSZhWs34k6UHlrrTB5t3gp3iTWxI3j6436c9p2E3ci6fyhtP1y3ycle1F5R+cogjGIecfgE2v6woyc1bbnjCdX/5V+/irbfvefX+Xef8ENNm6gXhZCE1YwQqiSSIAeAL24/3bRdnu6mfQ9mnlDv8XDeLu7PB196dNN26ULbBgCdKJBTlJVNbtdipg8PoCxtO2tj+JuCMcaYioOCMcaYioOCMcaYioOCMcaYioOCMcaYyrnURzksyGdsBsqOZ7TnNSkcs+fvwPcdz7YfCj+C465VCAXx2v1OWDRg4NKHWdhfdEzFw10EEBaupiqi6Mk8t3NFHBQAALuOx/Fh4coMKBUPsTqYReGUAyEx6zJfz+0VYZdBbAfU+PQL+fzYbDWVPcW0FkWDRj6HB4MqmkQW6QIf39GOK2rU9eTSzsAyiTUeuJpqIMcAgL3on4gNy0CKtQDAshJFoArfuP1xe5wQxbwGNd9CNSZsO1b7ds77vVDGDXxPpLWw5inXv2+7vVAIiecHhGpuIZ/h1QN8JorOIlSeZ/E3BWOMMRUHBWOMMRUHBWOMMRUHBWOMMRUHBWOMMZXzFdkJGfFMkRdVmyITo5uw4kqgbTyg7UUUYMm7tspOWUSRnZln8gfwcyq/mEzao/BumYV6Igg7oy6S2Ex8TgBgLaqEFFplBohCPZKJb1ESapApcJXRMgiPmq1QfBE1DC2+AmASQpONULcQqy0MvZB3CBXPMvD2aebnDETdVK7yY2yFWufChs9VtxA/H3U9AjWHZ+/h2p7aPTcKddhOKOy6ge/bedXO1UKKxgBAmETRIOXxJLZEJGZRk/DaGoSKMgh/L1XsaSAeSkmoidRzIkKoF4n30yTuh9i3kxVIGz+/McYY81UcFIwxxlQcFIwxxlQcFIwxxlQcFIwxxlTOpT665tNyWm4khAKY+laxEsErJPUTz/yPTJUDIBERRklcxbKP/Nh5K/xfhOqnxFZmVYSvUin8Ojvl9ZLbSdwJWddaHKKQymMAEKgrEBCISiKshA9P5kqt6Qqfw+6CUDzFdr4S8X0CgE5U2Zp7oXoh1apE0TnMQlGj/GxiJ/YKK17Htw/GkR97L5QmqwNyY4l7bdnyNU4rVRqQq5hyR9RUwlOs353Q9hjFsZkXz8wvKKkSc8LLKi/8OEtqnx8XxbVfkSojvj/VurFKaJk/DgCxJ8rAZYojeQZtpE1Uu2eTqIh4Fn9TMMYYU3FQMMYYU3FQMMYYU3FQMMYYUzlfojmjqXOhXslOJEEl6sMgi/fUe5L4AgBcbTM304onkC4t3IohdMLSoahXz9skTRHTF2cxbmHbMac2AdureD2qd/15cmrqRSJ3017PQpJk1zrzBFXYiDEubRGka+1kjbIoPCTsPLqZj6V07dhnkYTrRDY4ZJXgFLYDZI1SFBYSxPYFAOJFfs6F2JMEkQjvNnxPTMJeQRW36Waynuoe7Ln4AImPJZL7sxMJfzFsjCyzDy0oKDtirSE2xUCECgAwdcLOQuWlWUEmUrwIALrE79kiRCYbojTIovBQJh48s/LlOYO/KRhjjKk4KBhjjKk4KBhjjKk4KBhjjKk4KBhjjKmcT31UyrV/X0MUqf9/++f/smn70Of+Fe272nI1yPP+3ito+45YIzzi4uNp35sf/D20XRW46JRkhSgI5l6oO0ThoUmoW+LUXn8SSguIIiYTscoAgJVQUyG3S1+UGoKMDwB6dT2HQhFBVD9R2Vyo6xfXE4gtRhzbYkwAMG6478BK2K1MokBOT+wV/sUH/wfat9tw5ceD/vIW2n7rzU9u2vbjRdr3P77pmbR9ECqju7efp+33fuUrTVsmKjUAeNSNt9L2ruP78MHpEU3bTtxrSTyV+r34DJv4GP/8r/510/bRz7+L9t2JwlAv+r5/yk85X6DtBxcf1rTNQpGmFE9BtBdye4ae35vd3O7xbuZKzLP4m4IxxpiKg4IxxpiKg4IxxpiKg4IxxpiKg4IxxpjKudRHcw6Yz6hchJ0PRhJvVlev8ONe4ge5Io5dElGPBO63k0UmPwblT8TjZE6tukXYomAiBUUAIApTl5H4E61mvjQl83F3wj9qEmOMRDm1CAXTWhRaGZlXDoC054qIOBH1gyiak4VXUBHrCVIkZS8ETAfCm2rs1Li5z08p7XHSwhVPUfj83KDm9rhVtwxifEI0hX4SxYGE4muI7Z6YT/gxlsC9xibhz3RlaOdqGMS9qSx6elFMR/zCsmrnaxaPvJx40aC9kEL1M1cr9UQ1l4r47C3UYVtuB4Y1GUoQ3m7I5MZnbWxY19XLGGPMAwIHBWOMMRUHBWOMMRUHBWOMMRUHBWOMMZVzqY+6sEV3xthnBlcyrFZtVvx4w5UJfdnQ9oPliLYvc6tC6IkSBABC5oqNfN6ic0RBIIqDIYrqYDHw9hXxIdoLadNK+Q2pCkyqEhbxURmE0kJVQQsDV2wcCgUKc1Zazfw6lWosJf45Zu6JumXkyoyTxPfKIbgnEsh+uzaYdl5Cz1Vw45Utbb96gV/PgzbtvASxf/rA57AI1cu05sqZadvOS5/4HPaBX88kvI8OiNBmEt5HK7FnlYgnTWJ/7tv1DFs+V4c9V1Ml4m8FAGvwPZSJgi8TXy4ASPSOALpByMlI/zmKyn2pnds9qwpH8DcFY4wxFQcFY4wxFQcFY4wxFQcFY4wxFQcFY4wxlfNJcLrVtX+n4Nn5fWlVP1moOHpRve1k5iYggfj2ZFFJLYBn50MnPI6EP1Ek6qZJef8oNYgoyRaJB8ogjr0swhhlxY/d7/nczl2rKolCDZFFtbeDnm+fvTDjGYhiYxqEckSoRJR/VFrI9QuFTBj5HJ6IOVwTTyAASESVNa6EwmzFj7HmohccEnHLVijPJuYpBSCLinHTfbz/ilznfuR7YhL3PRZ+/WVujzMUfgzl1yWWHpH4kgHAxG6hnntT5cIXYlB+S1ksXGn3XKeqHyqPJ/FUnsmzrBeTsoxkL4/X97j3NwVjjDEVBwVjjDEVBwVjjDEVBwVjjDGV8yWax6/++xrSwBNLm137innfiYIiHU9mJWJdAAAbYovRi2OouLcIWwhFR4reJIhiOiKJDXHOiYxRvF2PdRBJRXU9whuADXFhyVoAcc+TWfNVPsiw4cm8iSTFRIkQaa2xdHxPJLL8e1HEpBMJ8iCKz6SFJ9pnIpBYjdxCAkHYcxzw5PG9sT32BV7rB0HYdiizhANiqwIAX1jaE2yCEDaMYjArfp27nuxPsfh8FQBRMwgQxaE2sR17Jw6+TfwHV8HXcy0sUVJuLyqoSmTgyeqgksfkeZMzH3eX2slibQx/UzDGGFNxUDDGGFNxUDDGGFNxUDDGGFNxUDDGGFM5l/ro33zmd3F44bTyh+sygI9//r1N25/+1Xto3/6KUCXdy20KevJa+yJe6VdFWbZCUXLY84I/u9yqEL7/8f8l7fv9j/ph2o4orCiITES8XY+sCnAIBUYRahDmMJBEMZA5iOI7a94eJz6HQ0fGvvB1K6KgDFOBXTt4q8D5Z//qv+J9F76vnv64f0zb/5MnvIiPhbQ9+3teQ/tuhIrlo3fxe+KPPvjGpm3ecLnO75c30fYk1kfUL0Iiup/uCr9PXv6MX+XHLvw6D48e2rSVRRSqWfi47z/5HG2fhHXF3eP9Tdu9936R9h0PL9D2J198Gj+nkDENpGjULFQ/RViF9JNQUob2/lFOGczGJ4tn4Vn8TcEYY0zFQcEYY0zFQcEYY0zFQcEYY0zFQcEYY0zlXOqj3CfkM0VR+sjVCUwlE67y0009j01jukLb+6H1HSmLKAbSce+WPh/R9kE4rxQQX5goCm2I9qC8R1izuJ4sFEyd9IXhzYWMZdsJBdPCVUl9EQWMhNIGrBCS8BsKwuNoJy6oJ04/m4mrUpaJ+9ZcFcqmNIl5IftWFVhKB2KvJD6Had1eZy+8nMKa7xVS7+XasUmRKgDo9+1abNf8nGPg930Re39ztb0Pw6UbaN9ZKM8yUfYAQExclRWvtM+PEPl8H0z8WVOEQdOgCud07Rg7cZ+oOkW54/szEKWeuGXpp33lKXU9v2uMMeYBioOCMcaYioOCMcaYioOCMcaYioOCMcaYyrnUR9N0gmk8rQzoVlzFk/aXm7bVSigWRBr+gJkCAdgTb5CoqhWdiJz7mkszTnref3XcZv6vTkJpIhQ/i/AeKSAKKWF+1BVRCUtUZIOoypVTu/RKnTCIinnLzFVG3VociQg2lGdVJ/ZEl4VX0tz23+9FZTyi7AGATqh4gqjUlonzTBAysP0k1p5vIYzk+rs9P/Ywcd8elBPaPIvKgB1ZoNAd0r5HomrYSRLKs6Htn2e+NwcxPiG8AzKflzm359wy/y0AUaiscifc3TIfY1ra9kns2U6YUAVRcZIWzBPPICxkTkYhRzuDvykYY4ypOCgYY4ypOCgYY4ypOCgYY4ypnCvRPIQNhnDa7mERSchNapM8i7BLmEaeQZonnqAZ1m1S9eQKTxIeiqTifsdfJV8G8d44aY4iIYZeFPwRWUVmu5AKTzbNAz9nYFlcAIt4rX8gifnMklMA9oW3HyS+bssJX4tlbM+ZVuIYxLYC0J9iwtSOMZCiJACwLsLOQlhUiMtHJHM7zHxfsUQ4AESRUF+RROYsEpD7kc93POAikF7cVyPZW1Elzgu3EOmFbUkhzwOidQCg9+Ey8GNPO2EjcdC2r8X9sIiCP72wVSlC2LEQm4vAKloBWESiOQu7lYEceyfEOJjb8S3Ckugs/qZgjDGm4qBgjDGm4qBgjDGm4qBgjDGm4qBgjDGmci71UeoS0plsd7qHZ+fvW9pM9ziLTL5QCOGQZ9bZW+MXj/ir/vsdz/BvVPGZwlUFc2xf3++FzcMsLDcg1AYdtf8Qr8CL1+shCpOoV+mZuqeIgi+rFT/G2ItCQEquQ5QSk3BFiJ1QU4nriUyVtRHWEonbP3TgyqGdKKjS79rj7zfC+kNYbqQ9tx7Y9a265yBuaN8QhD1H4AqhnPh1jlfb9l7M927g99tmK1RjZO3HyI89iM+qJfO5uiAsYQq5D8sVrjKKQiG0W/hcrSPf44kUAtoKmdWG2KQAwCzq98zkcb0WSi1WfSepijxn8DcFY4wxFQcFY4wxFQcFY4wxFQcFY4wxFQcFY4wxlVCKkFZ8DZcvX8alS5fw5b/6Mi5evHjqZ70oHANRzIIyC5VE4IU8xtxm0dfCb2gqfBxJKDYg/JkiURDMwqMkCGWCCsGBKFOC8GiB8kQSPky9UCUxCde8CHVU5Ne5E9q11Z7P4bxqx9IJrxxEsT6iYEkgyimyTa61C0Uaej7uIDyeqJfVohRzQvXSi01RSLEWodTqgyjKEsVciY04E4VQT/yqAADCIyxnvm5lau9lYQcF+UjJ3LtnL6rvDLGdF3E16ITX1iLmsIjnBLtvU+DHmFWBHHHvZ6JIHFRBL+KFdvnyZdz4kAfj/vvvb57jp04vf2KMMeYBh4OCMcaYioOCMcaYioOCMcaYioOCMcaYyrm8j0JfEM6ofHYiU95PrQohFVFhreP+Ip2oenTWfwkAMHEFhrBuQQl8LDHzKSlMxSOqUiXiiQMAWIvKRyvSXxigzEKUlJTKaOHXM5H+TN1w7eBcJbFSig2hPAukQlZZC7XXJCp4KfsWej2iK99uSMpzR0lWEtlzQu2mDrEIT6S4an+jW/NjF+GHtRAFEwAksZ49Uffsg6gCJq4ogisG86qdq5Xa47RVVx1cibHsl7Z/SsILbObHzsKvLYgHSyIquAVckZV68awRCjZ2W+Uk1F5kLxfhEXUWf1MwxhhTcVAwxhhTcVAwxhhTcVAwxhhTcVAwxhhTOZf6qEwFZTqtGFivhIKAVFWahHKmF+qJSYSstCNqA1XVTGkZOn7pws4IhXnuEDUNAIzKzkdcZyDLEIlvCwAE4UNUVBUncT1sznfinIvYJkmoPqTnDvGPikrxJOYwCCUHU1ss4tidOMYslDMdUxkBQGn7FzHfUah4klC3zOx6lAwqqn0lugvVGJhnF7vXAJSFL1Ag/lYAEIivVhH3YBSqpLiIPS4URavQXucsjpGErE3YXmEW6kU6W0pOpZ41aUfbM6kCF4Rako1bqevO4m8KxhhjKg4KxhhjKg4KxhhjKg4KxhhjKudKNPd9Qn/GYmISxSYSSYiqV/1llR/ymjoAFGJTMAsHiSjsH0ZxUlo4BUAkieyw5gnLKMY9CtsB7hQiEnaZt6uCMioxm3N70rU6iNglk3gdvxdjDD3LuPFjzKoojSoQQ5KKws0Bi7jOmEShJpHc78jOVcntuBMbbiWKCZFMeyc9Tvh8b0VSNSp7BVLwaBDFqxSLuq/YD8RH0izsY6AKMs1COEAuM05K2KAS/mIO54G25649Pnt2AEBQRizi2OhIMS6RIN+VbdO2LzyBfRZ/UzDGGFNxUDDGGFNxUDDGGFNxUDDGGFNxUDDGGFM5l/poiR2WM0qMuAh1SyGZ9VGoiUhWHQCKUImwt9r3QvESEz/nOgtpilArMbWOlFOxIkAAhrKn7YXZK0x8aYJQmixsfAAyKXYEAD0pbhOKsKdQ6yDmVhUVKQuxhZjUuvGxCHcFJLRzm4RHQRZ2I1FV8BGKmoXs/a4TyhG1bkFYa7BhiOHNQu226YVSS1xQR5Yti8IsYye8G8Q9Hog6bAn8GGUUFjRiTwyksM01WrVNUX3F/ZMyX58gnhOFqc/U/hFeLknNLZFTXRUf6wfit9IpD5Yz+JuCMcaYioOCMcaYioOCMcaYioOCMcaYioOCMcaYyrnURyETcU4RGXS0ZkSkJslXfyBik/B6WYgiohtEil+FvdYaBAAwdfx6Yt+qdZK4duFogixUFR0VHwlVzswvKLECKQB6McZCzKJUkZlMVBwAECIxoQIwCK+gkc35SqhVhEKoE7N7lUhzDsRcRVEESNWeUVVSYkcK4Qg1VQr8nLlw065l117PsOFrqeyJhCUQglD9ZLacyt9Kep6JG45cfxaqqZ56ZAF7MYfKE4mp+oLyVRIPiiwUg0l4KCVWSYwUlwIAUUsIRRTOCUSV1Itxd0Sm14lnwVn8TcEYY0zFQcEYY0zFQcEYY0zFQcEYY0zFQcEYY0zlXOqjuL/272tZkvDpGEh2XnkFMTMjAMOKt7MzzkJ9sxYqliwS8Z2qkkSUUMpKJCpbJTFGqsIQvkJJ+NnsidoLALqBq0d2pW3vOz7wICYrCVVOETKebmj7h8AnUa2PktSsyWJkohi7Nj7hCSSEKUHcJoWs5yqIz1nC3ytuhVfShvQXtxpmsQ5rYZakPHdye5zccfVNEEo1WalsYntcXBBT8AAoQhkYRLXETPyW5KfgRfmSiY24FnuIXFIK6oEgvMbEftsSE6WNUHBl8rBlbQx/UzDGGFNxUDDGGFNxUDDGGFNxUDDGGFNxUDDGGFM5l/po7gvmM0YrHfF/AQAQtUHohRkLUcIAwCS8QdigO5FZn4XfRxAVmPJe+PysWmMYpe0IogqcUhUQkQTiJJQCotJdv+ZqkP3CTZ6GftO0FaHiKGJ9srIQKsK7hqgn1kLxIw4NdEKZsmdKE+E3JNZnEL49Wax0mlrF19KJW2onPJFElb4ytWqYXeRKpWHNz5mIvxUATEIJlYgnVBYqI5DxAUAk++pae3v9e1JJDACSqPbWEXXUtYOLqmlkORfhs5bUdSbhTSWOM5N7PIpnTRK3+F48UjcTeZaJKm2FeFYV5TF3Bn9TMMYYU3FQMMYYU3FQMMYYU3FQMMYYUzlXorlDbouc7EQSkiVPRWGbqyIBHTtlOcGSOaLQhkh6RmVHQBLKAIClTZRN4jV1UTdG23yQBO8iXq8va5EkFDn8LvIEGqlJgywKqsSFzyFLkAOQ1xnpNfFEXhJFXPZCOLBiCcEdT8yGtbBFEIn2JIo9jV27VzqlpSAWH4BO7oMkFdfM+gKAKus0BjFXonAMFnI9HV+fWSSUsRNzS24rcafJjSUeB9iK+20glhuyAJYohLOIe2Jgth0AOpLEX7J4jolMcy+EEAsZYxI2MYlYiCSV2T6DvykYY4ypOCgYY4ypOCgYY4ypOCgYY4ypOCgYY4ypnEt9VGJBOfMqfIhcbpHJO+Zx4WqImLgaopuUVoAce8/HMQuJQxA/EG/MYybFLFaBK0rmnk9rFOqJmSihho5LtfJVPofLgVBsCMFKJsqMxCRJAKIauFBmLEJ+FNlgxKv3i1CgKIUUiEUDRNGgtHBVUkl8suae789hJPMyKPsDYWch5rxQGRM/xjzy61wNqlKRuH6ybYP43JgWYQcjVDzMcWQvLHKE4QQgitVsxB7KRJnTKwOVmbf3QtY3Rf78YHWd9sKKYiVUbVJmxcYoioKNRP7J2hj+pmCMMabioGCMMabioGCMMabioGCMMabioGCMMaZyLvVRiNf+fS1ZFBVpPJKglUAroTeYWSofQF/aLLxSAwxFmNEI36Ii2jtiaKRqfnTCK2gvlBkrYi+TO1GsRHjoZOLNdA2h4iGFY3LiSgZxSozKb2ktitIQlcwo9s8glCaixg4W4ZXEKIss4UNRBZlKvH5vnThxxY/6VMYUbEEU+1Eio1msj7AJo2NXxWRC5vdsH0RRGqIm6xfet2RRGEtIA5W/WY5kDoUPEXmkAADizNdNCAyxkOdNEus2CeWQ6h+IIq2IijwDuZcHoXQ7i78pGGOMqTgoGGOMqTgoGGOMqTgoGGOMqTgoGGOMqZxLfTShYDrjHVJmoYggMpEgqmwti6oeJBQlRBHRCY+SQipYAdJGBUEocJi6R1WGW5RfjJKmEA+lMAsPHeGtE7KI76I5lHYw1MsHAFZ84FFUfVKl1yaiHhnUnBCvKQCYRJU+kCpjnZCHhSwWvxcV1pRHDfHRSZnLWCahpIvCiyfv2rkdBlHVTKipkvKsEoqiQr28xBqL69mL/mzoyicpg69xEAqz0Atl10TuK+FvVYTXVhEKof3Cx7hm/m6Re2cVdf/MfN8u5JmaxL3Jtn6W2rjT+JuCMcaYioOCMcaYioOCMcaYioOCMcaYyrkSzREz4pniLEVkT0fyGnwvEspjFJYGohgKK6iiTA5UAZ+x56/pqwIfkVxnmcS78SJhqULwEtpjh1EkDyES56qYjkiqRlKsJvd8LYsYeCGFegBgIUlfAGB5tYUvD9JKFD1Rk0iKPS2Rj6MIm4ci7EkGkRAtOzLGDRdTqMI2mEUBn1V7TpFiRy/GN2e+nl3gBXK6pd39CytehL9G2CBsZQopuhWUmEAkfYdOLJxYt0jOqZ5XqjBUEpYbvSgQxG7PZRZPFVpICdiLcw47Yh3Ui/Xp2r5ZFJ06i78pGGOMqTgoGGOMqTgoGGOMqTgoGGOMqTgoGGOMqZxLfZTQIZ35lVmoYYauVQTMonhEL+Qgsyp4wxpFlQymsgEAJR7IQoUQSPyUmX9hdRCIyggAUmmVKUW8jq/KZExKZSSK7CARxQaxvgAAZGEjICYxaS1Ye+ik1Dp83LvM29dEaaPUFr2YxXkRtiWzUKZs2jUqoohLFAo7CKsUpqfrZiExE3YwRVUkmnkBJ/YRMYp9pQreRKE8o24eoujLID6rzmJfiTOi0CEKVV8WCjNq/QEU8VxhazGLdSg7PvLVWuw3psoSCrMtUd5NSnZ3Bn9TMMYYU3FQMMYYU3FQMMYYU3FQMMYYU7muRHP5ahL38uXj5mcz8w8H0JFEpko0R54RQj5HonkWieZuFq+19/zSg0w0t2OfRdJKWQDoRHN7/UUlq0VicprOl2gO50g0l6DsRnjzuRLNM080R5GcU4nmkRjITyIRLhPNwlpEWYgwK44iEn85njcp3+7PIhLNqgaIsovoee6Urmcp50s0q0QuRST2Rf5ZJ5rFvV/o+oukvEw0i/5KwEJsNPaqVgN3G0E/ikQzO6dKNJNrP758+dp5xXz9e64rKBwfXwsGj3rUY66nuzHGmG9Tjo+PcenSJfnzUP6msAEg54y77roLR0dHCKISkTHGmG9fSik4Pj7GzTffjCi+uQLXGRSMMcY8MHCi2RhjTMVBwRhjTMVBwRhjTMVBwRhjTMVBwRhjTMVBwRhjTMVBwRhjTOX/BQnVUDCSPhgtAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(image=dataset[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4B2jbM1ep2oy"
   },
   "source": [
    "## [Task 5] Two-Headed CNN Model Architecture - 1 Point\n",
    "\n",
    "<img src=\"./images/3.png\" width=\"65%\">\n",
    "\n",
    "### Description:\n",
    "Design a neural network with a shared backbone and two separate heads for predicting hours and minutes.\n",
    "\n",
    "### Steps:\n",
    "1. Use a pre-trained CNN from `torchvision` to retrieve images features.\n",
    "2. Add two new heads, one for hour classification and one for minute classification, each with its own fully connected layers.\n",
    "3. Implement the `forward` method to process input through the backbone and both heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "yT7p1gbkpzmU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "class TwoHeadedCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A neural network module with two heads, \n",
    "    designed for simultaneous hour and minute classification.\n",
    "\n",
    "    This module takes a backbone CNN model, \n",
    "    removes its last fully connected layer, and adds two separate\n",
    "    heads: one for hour classification and one for minute classification.\n",
    "\n",
    "    Args:\n",
    "        backbone (torch.nn.Module): A pre-trained CNN model to use as the backbone.\n",
    "        num_hour_classes (int, optional): Number of hour classes (default is 24).\n",
    "        num_minute_classes (int, optional): Number of minute classes (default is 60).\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone: torch.nn.Module,\n",
    "        num_hour_classes: int = 24,\n",
    "        num_minute_classes: int = 60,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Use the provided backbone model\n",
    "        # Remove the last fully connected layer\n",
    "        # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "        \n",
    "        # Hours head\n",
    "        # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "        # Minutes head\n",
    "        # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor to the network.\n",
    "\n",
    "        Returns:\n",
    "            tuple[torch.Tensor, torch.Tensor]: The outputs from the hours head and minutes head.\n",
    "        \"\"\"\n",
    "        # Forward pass through the backbone model\n",
    "        # Flatten the features\n",
    "        # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "        # Separate heads for hours and minutes\n",
    "        # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 6] Composite Loss Function - 0.5 Points\n",
    "\n",
    "### Description:\n",
    "Develop a loss function that computes the composite loss for a two-headed CNN model, accounting for both hour and minute predictions.\n",
    "\n",
    "### Steps:\n",
    "1. Complete the `composite_loss` function that accepts the model outputs and true labels for both hours and minutes.\n",
    "2. Use CrossEntropyLoss to calculate the loss for each head separately.\n",
    "3. Combine the individual losses into a single composite loss value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "\n",
    "def composite_loss(\n",
    "    model_output: tuple[torch.Tensor, torch.Tensor], \n",
    "    hour_labels: torch.Tensor, \n",
    "    minute_labels: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculates the composite loss for the two outputs of the model.\n",
    "\n",
    "    This function computes the CrossEntropyLoss for each output (hours and minutes) \n",
    "    and then combines them to create a composite loss.\n",
    "\n",
    "    Args:\n",
    "        model_output (tuple[torch.Tensor, torch.Tensor]): The outputs of the model, \n",
    "                                                          where the first tensor is hour predictions \n",
    "                                                          and the second tensor is minute predictions.\n",
    "        hour_labels (torch.Tensor): The true hour labels.\n",
    "        minute_labels (torch.Tensor): The true minute labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The composite loss value.\n",
    "    \"\"\"\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0S5NqWhp6Z9"
   },
   "source": [
    "## [Task 7] Training Loop - 1.25 Points\n",
    "\n",
    "### Description:\n",
    "Set up the training loop for the model using the provided configuration. This will involve writing `train_epoch` and `valid_epoch` functions, as well as the `main` function to initialize the model and datasets and to orchestrate the training process.\n",
    "\n",
    "### Steps:\n",
    "1. `train_epoch`: Write a function to train the model for one epoch, using the DataLoader to fetch data, the model to make predictions, the loss function to compute the loss, and the optimizer to update the model parameters.\n",
    "2. `valid_epoch`: Write a function to validate the model for one epoch. It should also use the DataLoader to fetch data and the model to make predictions, but it should not perform any parameter updates.\n",
    "3. `main`: Implement the main function to load data, create model instances, and call the training and validation functions in a loop for the desired number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "XXavMB9ap4ha"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Callable, Any\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: str | torch.device,\n",
    "    epoch: int,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Performs a single training epoch.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model to train.\n",
    "        dataloader (DataLoader): DataLoader for the training dataset.\n",
    "        loss_fn (Callable): Loss function used for training.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer for updating model weights.\n",
    "        device (str | torch.device): Device to which tensors will be moved ('cpu' or 'cuda').\n",
    "        epoch (int): Current epoch number.\n",
    "\n",
    "    Returns:\n",
    "        float: Average loss for this training epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch + 1} Training\")\n",
    "    for images, (hour_labels, minute_labels) in progress_bar:\n",
    "        # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def valid_epoch(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: str | torch.device,\n",
    "    epoch: int,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Performs a single validation epoch.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model to validate.\n",
    "        dataloader (DataLoader): DataLoader for the validation dataset.\n",
    "        loss_fn (Callable): Loss function used for validation.\n",
    "        device (str | torch.device): Device to which tensors will be moved ('cpu' or 'cuda').\n",
    "        epoch (int): Current epoch number.\n",
    "\n",
    "    Returns:\n",
    "        float: Average loss for this validation epoch.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch + 1} Validation\")\n",
    "    with torch.no_grad():\n",
    "        for images, (hour_labels, minute_labels) in progress_bar:\n",
    "            # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def main(config: dict[str, Any]) -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    Main training loop for the model.\n",
    "\n",
    "    This function sets up datasets, dataloaders, model, \n",
    "    loss function, and optimizer based on the provided configuration. \n",
    "    It then runs the training and validation loops for a specified number of epochs.\n",
    "\n",
    "    Args:\n",
    "        config (dict[str, Any]): Configuration dictionary containing parameters for training.\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.Module: Trained model.\n",
    "    \"\"\"\n",
    "    # Load datasets (train, valid)\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "    # Load dataloaders (train, valid)\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "    # Model and Optimizer\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "        print(f\"Epoch {epoch + 1} Summary: Train Loss: {train_loss:.4f}, Validation Loss: {valid_loss:.4f}\\n\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 8] Model Training - 1 Point\n",
    "\n",
    "### Description:\n",
    "Execute the model training using the defined configuration and save the trained model's state for future use.\n",
    "\n",
    "### Steps:\n",
    "1. Create a configuration dictionary with all the necessary parameters for the training process, including paths for the dataset, number of epochs, learning rate, and device specification.\n",
    "2. Call the `main` function with this configuration to train the model.\n",
    "3. After training, save the model's state dictionary so that the trained model can be loaded and used for inference later.\n",
    "\n",
    "### Testing:\n",
    "- Run the training process with the specified configuration to ensure it completes without errors.\n",
    "- Confirm that the model's state dictionary is saved correctly by loading it and verifying that it contains the expected parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-uhsgh9ep9Cr",
    "outputId": "b3284c71-55a5-4e98-f709-1c3495ef3386",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# Basic configuration - adjust paths and parameters as needed\n",
    "config = {\n",
    "    \"images_path\": \"( Õ°¬∞ Õú ñ Õ°¬∞ )\",\n",
    "    \"markup_path\": \"( Õ°¬∞ Õú ñ Õ°¬∞ )\",\n",
    "    \"splits_path\": \"( Õ°¬∞ Õú ñ Õ°¬∞ )\",\n",
    "    \"batch_size\": 1,\n",
    "    \"learning_rate\": 1e-10,\n",
    "    \"num_epochs\": 1,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"backbone\": models.resnet152(weights=models.resnet.ResNet152_Weights.DEFAULT)\n",
    "}\n",
    "\n",
    "model = main(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lmzmk8peqI8b"
   },
   "source": [
    "### Save model's state dict: (if you wish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "8PN1319RqBZ9"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48KIk7kgqNRg"
   },
   "source": [
    "## [Task 9] Model Inference - 0.5 Points\n",
    "\n",
    "### Description:\n",
    "Create a function to perform inference on a single image using a pre-trained model, converting the output to a human-readable time format.\n",
    "\n",
    "### Steps:\n",
    "1. Define an `infer_torch` function that accepts an image in numpy array format, the trained model, and the target image size for preprocessing.\n",
    "2. Inside the function, apply the necessary validation augmentations and preprocessing to prepare the image for the model.\n",
    "3. Convert the preprocessed image to a PyTorch tensor and feed it into the model to obtain the predicted hour and minute.\n",
    "4. Convert the model's output to a time string in the format 'HH:MM'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "aT8vcQ5HqOno"
   },
   "outputs": [],
   "source": [
    "def infer_torch(image: np.ndarray, model: torch.nn.Module, image_size=64) -> str:\n",
    "    \"\"\"\n",
    "    Performs inference on a single image using a trained model.\n",
    "\n",
    "    This function applies validation augmentations and preprocessing to the image, converts it to a\n",
    "    PyTorch tensor, and then uses the model to predict the time. The function outputs the predicted\n",
    "    time as a string.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The image to be processed and fed into the model.\n",
    "        model (torch.nn.Module): The trained model used for inference.\n",
    "        image_size (int, optional): The size to which the image will be resized.\n",
    "\n",
    "    Returns:\n",
    "        str: The predicted time as a string in the format 'HH:MM'.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Apply validation augmentations\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "    # Preprocess the image\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "    \n",
    "    # Convert the image to a PyTorch tensor, add batch dimension, put on device\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "    \n",
    "    # Predict using the model\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "    # Convert to time format\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing:\n",
    "- Use a sample image and a trained model to test the `infer_torch` function.\n",
    "- Display the original image and the predicted time to verify the function's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "ENw9SRkkqQVW"
   },
   "outputs": [],
   "source": [
    "image_path = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "image = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "predicted_time = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "Cluuhd6cqSxD",
    "outputId": "b3ecb86c-8ffb-400b-bbeb-93efca5f1bba"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Time: 15:53\n"
     ]
    }
   ],
   "source": [
    "visualize(image=image)\n",
    "print(\"Predicted Time:\", predicted_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77w8e30PrP_p"
   },
   "source": [
    "## [Task 10] Model Evaluation - 1 Point\n",
    "\n",
    "### Description:\n",
    "Write a function to assess the model's performance on the validation set by calculating accuracy, which is the proportion of correct predictions to total predictions.\n",
    "\n",
    "### Steps:\n",
    "1. Define an `evaluate_model` function that receives the model, paths to splits and targets, and the directory containing images.\n",
    "2. Load the validation set splits and corresponding targets.\n",
    "3. Iterate over the validation set, performing inference and comparing the predicted time to the actual time.\n",
    "4. Tally the correct predictions and calculate the accuracy.\n",
    "\n",
    "**(!!) To achieve full points for this task, the model's accuracy on the validation set must exceed 0.9. Make sure to fine-tune your model and preprocessing steps to meet this benchmark.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Two helper functions, special for you:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "W6JZOxzeqwuu"
   },
   "outputs": [],
   "source": [
    "def load_splits(splits_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Loads train/validation splits from a JSON file.\n",
    "\n",
    "    This function reads a JSON file specifying which images are in the training set\n",
    "    and which are in the validation set.\n",
    "\n",
    "    Args:\n",
    "        splits_path (str): The path to the JSON file containing the train/validation splits.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with keys 'train' and 'validation', each mapping to a list of image names.\n",
    "    \"\"\"\n",
    "    with open(splits_path, 'r') as file:\n",
    "        splits = json.load(file)\n",
    "    return splits\n",
    "\n",
    "\n",
    "def load_targets(targets_path: str) -> dict[str, str]:\n",
    "    \"\"\"\n",
    "    Loads target time labels for images from a file.\n",
    "\n",
    "    This function reads a file where each line contains a time label and an image name,\n",
    "    separated by ' -> '. It creates a dictionary mapping from image names to their corresponding\n",
    "    time labels.\n",
    "\n",
    "    Args:\n",
    "        targets_path (str): The path to the file containing the image names \n",
    "        and their corresponding time labels.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, str]: A dictionary where keys are image names \n",
    "        and values are their corresponding time labels.\n",
    "    \"\"\"\n",
    "    targets = {}\n",
    "    with open(targets_path, 'r') as file:\n",
    "        for line in file:\n",
    "            time_str, image_name = line.strip().split(' -> ')\n",
    "            targets[image_name] = time_str\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vov61_I0rR1X",
    "outputId": "97d55bf4-493b-42e4-f3da-fa8ad5617340"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    model: torch.nn.Module,\n",
    "    splits_path: str,\n",
    "    targets_path: str,\n",
    "    images_dir: str,\n",
    "    image_size: int = 64\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Evaluates model's accuracy on a validation set.\n",
    "\n",
    "    This function calculates the accuracy of the provided model by comparing its predictions\n",
    "    with the actual target times for each image in the validation set. It uses a specified\n",
    "    splits file to determine the images in the validation set and a targets file to get the\n",
    "    correct time labels.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained model to evaluate.\n",
    "        splits_path (str): Path to the JSON file containing the train/validation splits.\n",
    "        targets_path (str): Path to the file containing the image names and their corresponding time labels.\n",
    "        images_dir (str): Directory containing the images referenced in the targets file.\n",
    "        image_size (int, optional): Size to which the images should be resized.\n",
    "\n",
    "    Returns:\n",
    "        float: The accuracy of the model on the validation set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    splits = load_splits(splits_path)\n",
    "    targets = load_targets(targets_path)\n",
    "\n",
    "    # Metrics initialization\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    # Evaluate on the validation set\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "    # Calculate accuracy\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "    return accuracy\n",
    "\n",
    "splits_path = 'timer_dataset/splits.json'\n",
    "targets_path = 'timer_dataset/targets.txt'\n",
    "images_dir = 'timer_dataset/images/'\n",
    "\n",
    "accuracy = evaluate_model(model, splits_path, targets_path, images_dir)\n",
    "print(\"\\nAccuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert accuracy > 0.9, \"Try again!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 11] Model Conversion and Speed Benchmarking - 1 Point\n",
    "\n",
    "### Description:\n",
    "Convert the trained model to different runtimes (JIT, ONNX, TensorRT) and benchmark the inference speed. Document the results in a comparative table.\n",
    "\n",
    "### Steps:\n",
    "1. Use the original PyTorch model (referred to as 'Vanilla') and perform inference speed testing.\n",
    "2. Convert the model using JIT compilation and measure the inference speed.\n",
    "3. Use the Torch Compile API to compile the model and benchmark the speed.\n",
    "4. Convert the model to TensorRT and test inference speed.\n",
    "5. Convert the model to ONNX and test inference speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxr3akTsrqGg"
   },
   "source": [
    "**Vanilla**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "_c59VXLp2Gfl"
   },
   "outputs": [],
   "source": [
    "# Ensure, that the model in eval() mode, put it on the device\n",
    "model = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5I_C8bSBrVoX",
    "outputId": "6b03825b-12d6-4595-828e-515eab931064"
   },
   "outputs": [],
   "source": [
    "%%timeit -n 500\n",
    "image = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "infer_torch(image, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pc_39gQy3QPs"
   },
   "source": [
    "**Jit Tracing**\n",
    "\n",
    "Torch JIT tracing converts PyTorch models into an optimized, platform-independent format, boosting performance and simplifying deployment. It's useful for efficiently running models across different devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "MafeaWsG03n4"
   },
   "outputs": [],
   "source": [
    "# Create a dummy input for the tracing\n",
    "# ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "# Trace the model\n",
    "# ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42a-qoF73bhS",
    "outputId": "e53d53eb-8893-429b-913c-0c21a9b583ee"
   },
   "outputs": [],
   "source": [
    "%%timeit -n 500\n",
    "image = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "infer_torch(image, traced_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bajcqt3_rzon"
   },
   "source": [
    "**Torch Compile**\n",
    "\n",
    "`torch.compile` is a PyTorch feature that enhances performance by JIT-compiling PyTorch code into optimized kernels. This method speeds up code execution significantly with minimal changes to the existing codebase. It's a step beyond previous PyTorch compiler solutions like TorchScript and FX Tracing, offering more streamlined and efficient optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sv_obvHwr6SZ"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "opt_model = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z-w4JGdsr_74",
    "outputId": "eb8bee02-e8fe-411c-9e11-1ab092f9abb4"
   },
   "outputs": [],
   "source": [
    "%%timeit -n 500\n",
    "image = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "infer_torch(image, opt_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpxhTy663w0W"
   },
   "source": [
    "**TensorRT**\n",
    "\n",
    "`TensorRT`, developed by NVIDIA, significantly enhances the speed and efficiency of deep learning models on GPUs. It uses advanced optimization techniques such as layer fusion and precision calibration to maximize throughput and reduce latency. Designed for cross-platform compatibility, it supports various frameworks and is particularly effective in production environments where high-performance inference is crucial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "U4kgYqV64Deq",
    "outputId": "77f95873-ef40-446f-e85e-cd5c28934380"
   },
   "outputs": [],
   "source": [
    "import torch_tensorrt\n",
    "\n",
    "# Create a dummy input for the compile\n",
    "dummy_input = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "# Compile the model\n",
    "tensorrt_model = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_uc8psUc5WM2",
    "outputId": "955697c0-c7fa-4d9d-945c-e1310296f3c9"
   },
   "outputs": [],
   "source": [
    "%%timeit -n 500\n",
    "image = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "infer_torch(image, tensorrt_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqX8i-UN9Owb"
   },
   "source": [
    "**ONNX**\n",
    "\n",
    "`ONNX (Open Neural Network Exchange)` is an open format designed to represent machine learning models. It enables models to be transferred between different frameworks, ensuring interoperability and flexibility. ONNX is widely used for model sharing and deployment across various platforms and tools, making it valuable for developers working in diverse environments or with multiple machine learning frameworks. Its ability to standardize model representation simplifies the process of model exchange and deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fJ1-Ykq39InI",
    "outputId": "9c3590ac-3b67-4aea-eaf6-8bd5020deb9e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "\n",
    "# Create a dummy input for the export\n",
    "dummy_input = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "# Export the model, saving it like \"model.onnx\"\n",
    "# ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "DXbdtezB-hFb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "\n",
    "\n",
    "def infer_onnx(\n",
    "    image: np.ndarray,\n",
    "    session: ort.InferenceSession,\n",
    "    image_size: int = 64\n",
    "  ) -> str:\n",
    "    \"\"\"\n",
    "    Performs inference on a single image using an ONNX model session.\n",
    "\n",
    "    This function applies validation augmentations and preprocessing to the image, converts it to the\n",
    "    format expected by the ONNX model, and then uses the session to predict the time. The function\n",
    "    outputs the predicted time as a string.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The image to be processed and fed into the ONNX model.\n",
    "        session (ort.InferenceSession): The ONNX model inference session.\n",
    "        image_size (int, optional): The size to which the image will be resized.\n",
    "\n",
    "    Returns:\n",
    "        str: The predicted time as a string in the format 'HH:MM'.\n",
    "    \"\"\"\n",
    "    # Get ONNX model input_name\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "    # Apply validation augmentations\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "    # Preprocess the image\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "    \n",
    "    # Convert the image to the batch expected by ONNX, cast to float\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "    # Predict using the ONNX session\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "    # Assuming the model returns two outputs: hour and minute\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "\n",
    "    # Convert to time format\n",
    "    # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "    return time_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "z0jHJv23GM9D"
   },
   "outputs": [],
   "source": [
    "# We initialize a session first\n",
    "session = ort.InferenceSession(\"model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_H7yiLncCQ_-",
    "outputId": "ecda4c48-87c5-4520-bef9-da6005eb0791"
   },
   "outputs": [],
   "source": [
    "%%timeit -n 500\n",
    "image = # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü YOUR CODE HERE\n",
    "infer_onnx(image, session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the table:\n",
    "\n",
    "| Runtime   | Number of Loops | Mean Inference Time (ms) | Standard Deviation (ms) |\n",
    "|-----------|-----------------|--------------------------|-------------------------|\n",
    "| Vanilla   | 500             | TBD                      | TBD                     |\n",
    "| JIT       | 500             | TBD                      | TBD                     |\n",
    "| Compile   | 500             | TBD                      | TBD                     |\n",
    "| TensorRT  | 500             | TBD                      | TBD                     |\n",
    "| ONNX      | 500             | TBD                      | TBD                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comments on results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(0_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBKQvEW8SpLC"
   },
   "source": [
    "## [Task 12] Rust - 3 Points\n",
    "\n",
    "<img src=\"./images/4.jpeg\" width=50%>\n",
    "\n",
    "### About Rust:\n",
    "Rust is a programming language known for its focus on safety and performance. It's designed to be memory safe, preventing common bugs seen in languages like C and C++. Rust achieves this through its unique ownership system, which manages memory and other resources at compile time, eliminating many runtime errors.\n",
    "\n",
    "Its performance is comparable to C++, making it suitable for systems programming and applications where speed is critical. Rust also offers modern features like zero-cost abstractions, guaranteed memory safety, and a friendly compiler with useful error messages, enhancing developer experience.\n",
    "\n",
    "Rust is increasingly popular in areas such as web assembly, embedded systems, and networking, as well as for building command-line tools and desktop applications. Its growing community and rich ecosystem of tools and libraries contribute to its rising adoption.\n",
    "\n",
    "\n",
    "### Suggested Materials:\n",
    "- \"Rust by Example\": A collection of runnable examples that illustrate various Rust concepts and standard libraries.\n",
    "- \"Rustlings\": A fun, instructive way to get accustomed to reading and writing Rust syntax through small exercises.\n",
    "- \"Maturin\": A tool specifically designed for creating Python extensions in Rust with ease. It integrates seamlessly with Cargo and PyPI, simplifying the process of building and distributing Rust-written Python modules. Ideal for enhancing Python with Rust‚Äôs performance and safety features, Maturin makes it straightforward to package and share Rust code as Python packages.\n",
    "\n",
    "### Why Infer in Rust:\n",
    "Rust is good for machine learning inference, offering safety and high performance. It avoids latency issues common with garbage collectors and its type system and concurrency model enable efficient, maintainable code. Rust's capabilities allow for serverless inference with lightweight binaries, addressing the slowness of large frameworks like PyTorch in cluster instances. It also reduces Python's performance overhead, a notable advantage given Python's Global Interpreter Lock (GIL) challenges. Rust's growing popularity in the machine learning ecosystem.\n",
    "\n",
    "Finally, Rust is cool!\n",
    "\n",
    "---\n",
    "\n",
    "### Description:\n",
    "The task involves enhancing a machine learning workflow by integrating Rust's performance capabilities with Python's flexibility. The goal is to use Rust for running an ONNX model inference, and then create Python bindings to utilize the Rust implementation. This hybrid approach aims to leverage Rust's performance and safety while maintaining the ease of use provided by Python.\n",
    "\n",
    "The project structure includes:\n",
    "```\n",
    ".\n",
    "‚îú‚îÄ‚îÄ Cargo.toml\n",
    "‚îú‚îÄ‚îÄ images\n",
    "‚îú‚îÄ‚îÄ HW6.ipynb\n",
    "‚îú‚îÄ‚îÄ model.onnx\n",
    "‚îú‚îÄ‚îÄ example.png\n",
    "‚îú‚îÄ‚îÄ src\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ lib.rs\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ main.rs\n",
    "‚îî‚îÄ‚îÄ timer_dataset\n",
    "```\n",
    "\n",
    "- An example image file `example.png` which could be used for testing the inference process.\n",
    "- A `model.onnx` file which is our converted model to be used for inference.\n",
    "- A `Cargo.toml` file indicating the Rust project's dependencies.\n",
    "- A source directory `src` containing the Rust source code:\n",
    "  - `lib.rs` which is a Rust library file containing shared logic or definitions.\n",
    "  - `main.rs` which is the Rust main file, containing the entry point of the Rust application.\n",
    "\n",
    "**The `.rs` files in the source directory are almost complete but contain errors that need to be fixed. After correcting these errors, you are expected to compile the Rust source into a binary. This binary will be a production-ready executable that performs the ONNX model inference.**\n",
    "\n",
    "**The second part of the task is to build Python bindings using `maturin`. These bindings will allow Python scripts to call the Rust binary and perform inference. The binding should provide an interface where Python code can pass the paths of the model and image files, and then receive the inference results. The results expected are a string representing the predicted outcome and a float64 value indicating the elapsed time of the model call in Rust.**\n",
    "\n",
    "### Steps:\n",
    "1. Debug and correct the Rust code provided in `.rs` files.\n",
    "2. Compile the corrected Rust code into a production-ready binary for ONNX model inference.\n",
    "3. Create Python bindings for the Rust binary to allow inference from Python, ensuring the binding returns the predicted time as a string and the elapsed time as a float64."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Binary - 1 Point\n",
    "\n",
    "Compile a Rust binary that performs ONNX model inference and accurately predicts time from an image.\n",
    "\n",
    "Instructions:\n",
    "1. Compile the Rust binary using the provided command. Ensure all dependencies are correctly installed for a successful build.\n",
    "2. Run the binary with an image to perform inference. The program should output the time taken for inference and the predicted time.\n",
    "\n",
    "Criteria for Full Points:\n",
    " - The Rust binary compiles without errors.\n",
    " - Upon execution, the binary prints out the time taken for the inference process and the correct predicted time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kqxt8F9UL3Ch",
    "outputId": "522e4628-f91a-45c9-b8da-0ce0ffb4dcde"
   },
   "outputs": [],
   "source": [
    "!cargo build --bin binary -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3qGSDEwSYB08",
    "outputId": "335fe56d-98e8-47c1-d8c8-f9fe9096fc92"
   },
   "outputs": [],
   "source": [
    "!./target/release/binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Python Binding - 2 Points\n",
    "\n",
    "Build a Python binding for the Rust-based ONNX inference engine and validate its functionality through a Python interface.\n",
    "\n",
    "Instructions:\n",
    "1. Use maturin to build the Python binding from the Rust implementation.\n",
    "2. Install the generated wheel using pip to make the binding available to Python.\n",
    "3. In Python, import the provided binding function and pass the paths of the ONNX model and an image file to it.\n",
    "4. Check that the function returns the correct prediction and the model's call time measured in Rust.\n",
    "\n",
    "Criteria for Full Points:\n",
    " - The Python binding compiles and installs without errors.\n",
    " - The Python code successfully calls the Rust inference engine and returns the correct prediction and elapsed time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binding build and library install:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bPOCxt4vbsbx",
    "outputId": "f047ae59-6b15-4d47-b5de-a057ebac4b3d"
   },
   "outputs": [],
   "source": [
    "!maturin build -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3tMxYuobzRX",
    "outputId": "32c8d783-bb26-4151-bcc8-5bd03063f1fc"
   },
   "outputs": [],
   "source": [
    "!pip install # ‚ï∞( Õ°¬∞ Õú ñ Õ°¬∞ )„Å§‚îÄ‚îÄ‚òÜ*:„ÉªÔæü"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binding test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "hicxOvOkfZ-9"
   },
   "outputs": [],
   "source": [
    "from onnx_inference import run_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "mCQxriGefeRd"
   },
   "outputs": [],
   "source": [
    "predict, elapsed_time = run_model(\"model.onnx\", \"example.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Time:\", predict, \"\\nElapsed time:\", elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert predict == \"15:53\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
